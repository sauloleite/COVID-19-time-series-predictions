{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição de séries temporais da COVID-19\n",
    "### Casos confirmados\n",
    "\n",
    "Autor: Saulo Leite\n",
    "\n",
    "Dissertação: PREDIÇÃO DE SÉRIES TEMPORAIS DA COVID-19: UMA AVALIAÇÃO DE REDES NEURAIS COM ARIMA, LSTM, MLP & ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas\n",
    "Para a implementação desse trabalho, foram necessárias muitas bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import pandas\n",
    "from pandas import read_csv\n",
    "from pandas import Series\n",
    "from urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt, ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de dados\n",
    "\n",
    "Os dados usados neste trabalho são disponibilizados pela Universidade Johns Hopkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "#urlretrieve(url, 'datasets/casos_covid19.csv')\n",
    "df_covid = pandas.read_csv('datasets/casos_covid19.csv')\n",
    "df_covid.drop(['Lat', 'Long'], axis=1, inplace=True)\n",
    "df_country = df_covid.groupby('Country/Region').sum()\n",
    "df_country.loc[['Brazil', 'India', 'US', 'Italy']]\n",
    "s_brazil = df_country.loc['Brazil']\n",
    "s_india = df_country.loc['India']\n",
    "s_us = df_country.loc['US']\n",
    "s_italy = df_country.loc['Italy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando dados completos\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.xticks(color='w')\n",
    "plt.plot(s_brazil.index, s_brazil.values, label = 'Brasil', color = 'green')\n",
    "plt.plot(s_us.index, s_italy.values, label = 'Itália', color = 'yellow')\n",
    "plt.plot(s_india.index, s_india.values, label = 'Índia', color = 'blue')\n",
    "plt.plot(s_us.index, s_us.values, label = 'EUA', color = 'red')\n",
    "plt.title('Total de casos confirmados de COVID-19 de Brasil, Índia, Itália e EUA')\n",
    "plt.xlabel(\"2020-2021\")\n",
    "plt.ylabel(\"Total de infectados\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando os dados em parte\n",
    "tam = len(s_brazil)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.xticks(rotation = 90)\n",
    "plt.plot(s_brazil.index[tam-80:tam], s_brazil.values[tam-80:tam], label = 'Brasil')\n",
    "plt.plot(s_india.index[tam-80:tam], s_india.values[tam-80:tam], label = 'Índia')\n",
    "plt.plot(s_italy.index[tam-80:tam], s_italy.values[tam-80:tam], label = 'Itália')\n",
    "plt.plot(s_us.index[tam-80:tam], s_us.values[tam-80:tam], label = 'EUA')\n",
    "plt.title('Total de casos confirmados de COVID-19 de Brasil, Índia, Itália e EUA nos últimos meses')\n",
    "plt.xlabel(\"Dias\")\n",
    "plt.ylabel(\"Total de infectados\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportação de dados totais\n",
    "#Contabilizar os dias que estão com \"zero casos\"\n",
    "#Estudar caso de inputação baysiana\n",
    "s_brazil = s_brazil[s_brazil > 0]\n",
    "s_india = s_india[s_india > 0]\n",
    "s_italy = s_italy[s_italy > 0]\n",
    "s_us = s_us[s_us > 0]\n",
    "s_brazil.to_csv('datasets/countries/casos_covid19_brazil.csv')\n",
    "s_india.to_csv('datasets/countries/casos_covid19_india.csv')\n",
    "s_italy.to_csv('datasets/countries/casos_covid19_italy.csv')\n",
    "s_us.to_csv('datasets/countries/casos_covid19_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação dos modelos LSTM e MLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter uma matriz de valores em uma matriz de conjunto de dados\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country = ['Brasil', 'Índia', 'Itália', 'EUA'] #Lista de países\n",
    "\n",
    "#Grid Search\n",
    "T_A = [0.01, 0.05, 0.1, 0.2] #0.01, 0.02, 0,03, 0.06, 0.1, 0.2; \n",
    "DROP = [0.01, 0.05, 0.1, 0.2]   #0.05, 0.1, 0.15, 0.2, 0.3, 0.5;\n",
    "N_C = [200, 300, 400, 600]    #50, 100, 200, 300, 400, 600;\n",
    "NPC = [8, 16, 32, 64] #Neurônios por camada\n",
    "\n",
    "#Dicionários LSMT\n",
    "dts = {} #Dicionário de datasets \n",
    "trpp = {} #Dicionário de treinos\n",
    "tspp = {} #Dicionário de testes\n",
    "trs = {} #Dicionário de scores de treinos \n",
    "tss = {} #Dicionário de scores de testes\n",
    "tsm = {} #Dicionário de MAES\n",
    "\n",
    "#Valores selecionados (Melhores valores)\n",
    "strpp = {} #Dicionário de treinos\n",
    "stspp = {} #Dicionário de testes\n",
    "strs = {} #Dicionário de scores de treinos \n",
    "stss = {'Brasil':(9**15), 'Índia':(9**15), 'EUA':(9**15),'Itália':(9**15)} #Dicionário de scores de testes\n",
    "stsm = {'Brasil':(9**15), 'Índia':(9**15), 'EUA':(9**15),'Itália':(9**15)} #Dicionário de MAE's Saída\n",
    "\n",
    "#Dicionários MLP\n",
    "dtsMLP = {} #Dicionário de datasets \n",
    "trppMLP = {} #Dicionário de treinos\n",
    "tsppMLP = {} #Dicionário de testes\n",
    "trsMLP = {} #Dicionário de scores de treinos \n",
    "tssMLP = {} #Dicionário de scores de testes\n",
    "t_aMLP = {} #Dicionário de taxa de aprendizagem\n",
    "tsmMLP = {} #Dicionário de MAES\n",
    "\n",
    "#Valores selecionados (Melhores valores)\n",
    "strppMLP = {} #Dicionário de treinos\n",
    "stsppMLP = {} #Dicionário de testes\n",
    "strsMLP = {} #Dicionário de scores de treinos \n",
    "stssMLP = {'Brasil':(9**15), 'Índia':(9**15), 'EUA':(9**15),'Itália':(9**15)} #Dicionário de scores de testes\n",
    "stsmMLP = {'Brasil':(9**15), 'Índia':(9**15), 'EUA':(9**15),'Itália':(9**15)} #Dicionário de MAE's Saída\n",
    "\n",
    "st_aMLP = {} #Dicionário de taxa de aprendizagem saída\n",
    "\n",
    "#Ajustes para seleção LSTM\n",
    "t_a = {} #Dicionário de taxa de aprendizagem\n",
    "dropout = {} #Dicionário de dropout\n",
    "n_cel = {} #Dicionário de número de células\n",
    "st_a = {} #Dicionário de taxa de aprendizagem saída\n",
    "sdropout = {} #Dicionário de dropout saída\n",
    "sn_cel = {} #Dicionário de número de células saída\n",
    "\n",
    "#Ajustes para seleção MLP\n",
    "t_a = {} #Dicionário de taxa de aprendizagem\n",
    "dropoutMLP = {} #Dicionário de dropout\n",
    "n_neu = {} #Dicionário de número de neurônios\n",
    "st_aMLP = {} #Dicionário de taxa de aprendizagem saída\n",
    "sdropoutMLP = {} #Dicionário de dropout saída\n",
    "sn_neu = {} #Dicionário de número de neurônios\n",
    "\n",
    "#Armazenando testes para plotagem somente dos testes\n",
    "\n",
    "testP = {}\n",
    "testPMLP = {}\n",
    "stestPMLP = {}\n",
    "testPred = {}\n",
    "testPredMLP = {}\n",
    "stestPred = {}\n",
    "stestPredMLP = {}\n",
    "\n",
    "#Relizando grade de experimentos\n",
    "\n",
    "for i in range(len(country)):\n",
    "    for z in range(len(T_A)):\n",
    "        for j in range(len(DROP)):\n",
    "            for k in range(len(N_C)):\n",
    "                if country[i] == 'Brasil':\n",
    "                    dataframe = read_csv('datasets/countries/casos_covid19_brazil.csv', usecols=[1], engine='python')\n",
    "                    dataset = dataframe.values\n",
    "                    dataset = dataset.astype('float32')\n",
    "                if country[i] == 'Índia':\n",
    "                    dataframe = read_csv('datasets/countries/casos_covid19_india.csv', usecols=[1], engine='python')\n",
    "                    dataset = dataframe.values\n",
    "                    dataset = dataset.astype('float32')\n",
    "                if country[i] == 'Itália':\n",
    "                    dataframe = read_csv('datasets/countries/casos_covid19_italy.csv', usecols=[1], engine='python')\n",
    "                    dataset = dataframe.values\n",
    "                    dataset = dataset.astype('float32')\n",
    "                if country[i] == 'EUA':\n",
    "                    dataframe = read_csv('datasets/countries/casos_covid19_us.csv', usecols=[1], engine='python')\n",
    "                    dataset = dataframe.values\n",
    "                    dataset = dataset.astype('float32')\n",
    "                \n",
    "                #LSTM\n",
    "                \n",
    "                # Normalizar o dataset\n",
    "                scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "                dataset = scaler.fit_transform(dataset)\n",
    "                # dividir em conjuntos de treinamento e teste\n",
    "                train_size = int(len(dataset) * 0.67)\n",
    "                test_size = len(dataset) - train_size\n",
    "                train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "                # remodelar em X = t e Y = t + 1\n",
    "                look_back = 1\n",
    "                trainX, trainY = create_dataset(train, look_back)\n",
    "                testX, testY = create_dataset(test, look_back)\n",
    "                # remodelar a entrada para ser [amostras, intervalos de tempo, recursos]\n",
    "                trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "                testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "                #Criando modelo\n",
    "                model = Sequential()\n",
    "                keras.backend.set_epsilon(1)\n",
    "                #Adicionando camada LSTM e alguma regularização de Dropout \n",
    "                model.add(LSTM(units=int(N_C[k])))\n",
    "                model.add(Dropout(float(DROP[j])))\n",
    "                model.add(Dense(units=1, activation='linear'))\n",
    "                #definindo hiper parâmetros\n",
    "                adam = keras.optimizers.Adam(learning_rate=float(T_A[z]), beta_1=0.999, beta_2=0.999, amsgrad=False)\n",
    "                model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "                model.fit(trainX, trainY, epochs=200, batch_size=40) #Mudar para 300 épocas - fora do grid search\n",
    "                #fazer previsões\n",
    "                trainPredict = model.predict(trainX)\n",
    "                testPredict = model.predict(testX)\n",
    "                # inverter previsões\n",
    "                trainPredict = scaler.inverse_transform(trainPredict)\n",
    "                trainY = scaler.inverse_transform([trainY])\n",
    "                testPredict = scaler.inverse_transform(testPredict)\n",
    "                testY = scaler.inverse_transform([testY])\n",
    "                # calcular raiz quadrada média do erro\n",
    "                trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "                print('Train Score: %.2f RMSE' % (trainScore))\n",
    "                testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "                print('Test Score: %.2f RMSE' % (testScore))\n",
    "                #Calcular o MAE:\n",
    "                MAE = mean_absolute_error(testY[0], testPredict[:,0])\n",
    "                # mudar para treinar previsões para traçar\n",
    "                trainPredictPlot = numpy.empty_like(dataset)\n",
    "                trainPredictPlot[:, :] = numpy.nan\n",
    "                trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "                # previsões de teste de deslocamento para plotagem\n",
    "                testPredictPlot = numpy.empty_like(dataset)\n",
    "                testPredictPlot[:, :] = numpy.nan\n",
    "                testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "                \n",
    "                #MLP\n",
    "                train_size = int(len(dataset) * 0.67)\n",
    "                test_size = len(dataset) - train_size\n",
    "                train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "                # remodelar em X = t e Y = t + 1\n",
    "                look_back = 1\n",
    "                trainX, trainY = create_dataset(train, look_back)\n",
    "                testX, testY = create_dataset(test, look_back)\n",
    "                # remodelar a entrada para ser [amostras, intervalos de tempo, recursos]\n",
    "                trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "                testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "                model = Sequential()\n",
    "                model.add(Dense(NPC[i], activation='sigmoid', input_dim = 1))\n",
    "                model.add(Dropout(float(DROP[j])))\n",
    "                model.add(Dense(NPC[i], activation='tanh'))\n",
    "                model.add(Dropout(float(DROP[j])))\n",
    "                model.add(Dense(NPC[i], activation='relu'))\n",
    "                model.add(Dropout(float(DROP[j])))\n",
    "                model.add(Dense(1))\n",
    "                adam = keras.optimizers.Adam(learning_rate=float(T_A[z]))\n",
    "                model.compile(optimizer=adam , loss='mean_squared_error')\n",
    "                model.fit(trainX, trainY, epochs=200, batch_size = 40)\n",
    "                #fazer previsões\n",
    "                trainPredictMLP = model.predict(trainX)\n",
    "                testPredictMLP = model.predict(testX)\n",
    "                # inverter previsões\n",
    "                trainPredictMLP = scaler.inverse_transform(trainPredictMLP)\n",
    "                trainY = scaler.inverse_transform([trainY])\n",
    "                testPredictMLP = scaler.inverse_transform(testPredictMLP)\n",
    "                testY = scaler.inverse_transform([testY])\n",
    "                # calcular raiz quadrada média do erro\n",
    "                trainScoreMLP = math.sqrt(mean_squared_error(trainY[0], trainPredictMLP[:,0]))\n",
    "                print('Train Score MLP: %.2f RMSE' % (trainScoreMLP))\n",
    "                testScoreMLP = math.sqrt(mean_squared_error(testY[0], testPredictMLP[:,0]))\n",
    "                print('Test Score MLP: %.2f RMSE' % (testScoreMLP))\n",
    "                #Calcular o MAE:\n",
    "                MAEMLP = mean_absolute_error(testY[0], testPredictMLP[:,0])\n",
    "                # mudar para treinar previsões para traçar\n",
    "                trainPredictPlotMLP = numpy.empty_like(dataset)\n",
    "                trainPredictPlotMLP[:, :] = numpy.nan\n",
    "                trainPredictPlotMLP[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "                # previsões de teste de deslocamento para plotagem\n",
    "                testPredictPlotMLP = numpy.empty_like(dataset)\n",
    "                testPredictPlotMLP[:, :] = numpy.nan\n",
    "                testPredictPlotMLP[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "\n",
    "                #Armazenando as informações em dicionários LSTM\n",
    "                tss[country[i]] = testScore\n",
    "                tsm[country[i]] = MAE\n",
    "                trpp[country[i]] = trainPredictPlot\n",
    "                tspp[country[i]] = testPredictPlot\n",
    "                trs[country[i]] = trainScore\n",
    "                dts[country[i]] = scaler.inverse_transform(dataset)\n",
    "                t_a[country[i]] = T_A[z]\n",
    "                dropout[country[i]] = DROP[j]\n",
    "                n_cel[country[i]] = N_C[k]\n",
    "                tsm[country[i]] = MAE\n",
    "                trainP[country[i]] = scaler.inverse_transform(train)\n",
    "                testP[country[i]] = scaler.inverse_transform(test)\n",
    "                testPred[country[i]] = testPredict\n",
    "                if tss[country[i]] < stss[country[i]]: #Condição de verificação dos melhores resultados\n",
    "                    strpp[country[i]] = trainPredictPlot\n",
    "                    stspp[country[i]] = testPredictPlot\n",
    "                    strs[country[i]] = trainScore\n",
    "                    stss[country[i]] = testScore\n",
    "                    st_a[country[i]] = T_A[z]\n",
    "                    sdropout[country[i]] = DROP[j]\n",
    "                    sn_cel[country[i]] = N_C[k]\n",
    "                    stsm[country[i]] = MAE\n",
    "                    stestPred[country[i]] = testPredict\n",
    "                #Armazenando as informações em dicionários MLP\n",
    "                tssMLP[country[i]] = testScoreMLP\n",
    "                trppMLP[country[i]] = trainPredictPlotMLP\n",
    "                tsppMLP[country[i]] = testPredictPlotMLP\n",
    "                trsMLP[country[i]] = trainScoreMLP\n",
    "                t_aMLP[country[i]] = T_A[z]\n",
    "                dropoutMLP[country[i]] = DROP[j]\n",
    "                n_neu[country[i]] = NPC[i]\n",
    "                tsmMLP[country[i]] = MAEMLP\n",
    "                testPredMLP[country[i]] = testPredictMLP\n",
    "                \n",
    "                if tssMLP[country[i]] < stssMLP[country[i]]: #Condição de verificação dos melhores resultados\n",
    "                    strppMLP[country[i]] = trainPredictPlotMLP\n",
    "                    stsppMLP[country[i]] = testPredictPlotMLP\n",
    "                    strsMLP[country[i]] = trainScoreMLP\n",
    "                    stssMLP[country[i]] = testScoreMLP\n",
    "                    st_aMLP[country[i]] = T_A[z]\n",
    "                    sdropoutMLP[country[i]] = DROP[j]\n",
    "                    sn_neu[country[i]] = NPC[i]\n",
    "                    stsmMLP[country[i]] = MAEMLP\n",
    "                    stestPredMLP[country[i]] = testPredictMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar gráficos com os testes LSTM\n",
    "for i in range(len(country)): #loop de repatição apra mostrar todos os países\n",
    "    print('\\n LSTM - O melhor caso - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com LSTM' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(testP[country[i]], label = 'Dados reais')\n",
    "    plt.plot(stestPred[country[i]], label = 'Predição')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Test Score: %.2f RMSE' % (stss[country[i]]))\n",
    "    print('MAE:', stsm[country[i]])\n",
    "    print('Taxa de aprendizagem:', st_a[country[i]])\n",
    "    print('Dropout:', sdropout[country[i]])\n",
    "    print('Número de células:', sn_cel[country[i]])\n",
    "\n",
    "    print('\\n LSTM - O segundo melhor - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com LSTM' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(testP[country[i]], label = 'Dados reais')\n",
    "    plt.plot(testPred[country[i]], label = 'Predição')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Test Score: %.2f RMSE' % (tss[country[i]]))\n",
    "    print('MAE:', tsm[country[i]])\n",
    "    print('Taxa de aprendizagem:', t_a[country[i]])\n",
    "    print('Dropout:', dropout[country[i]])\n",
    "    print('Número de células:', n_cel[country[i]])\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar gráficos com base nas previsões do modelo LSTM\n",
    "for i in range(len(country)): #loop de repatição apra mostrar todos os países\n",
    "    \n",
    "    print('\\n LSTM - O melhor caso - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com LSTM' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(dts[country[i]], label = 'Dados reais')\n",
    "    plt.plot(strpp[country[i]], label = 'Predição de treino')\n",
    "    plt.plot(stspp[country[i]], label = 'Predição de teste')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Train Score: %.2f RMSE' % (strs[country[i]]))\n",
    "    print('Test Score: %.2f RMSE' % (stss[country[i]]))\n",
    "    print('MAE:', stsm[country[i]])\n",
    "    print('Taxa de aprendizagem:', st_a[country[i]])\n",
    "    print('Dropout:', sdropout[country[i]])\n",
    "    print('Número de células:', sn_cel[country[i]])\n",
    "\n",
    "    print('\\n LSTM - O segundo melhor - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com LSTM' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(dts[country[i]], label = 'Dados reais')\n",
    "    plt.plot(trpp[country[i]], label = 'Predição de treino')\n",
    "    plt.plot(tspp[country[i]], label = 'Predição de teste')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Train Score: %.2f RMSE' % (trs[country[i]]))\n",
    "    print('Test Score: %.2f RMSE' % (tss[country[i]]))\n",
    "    print('MAE:', tsm[country[i]])\n",
    "    print('Taxa de aprendizagem:', t_a[country[i]])\n",
    "    print('Dropout:', dropout[country[i]])\n",
    "    print('Número de células:', n_cel[country[i]])\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    #Armazenando dados de treino e teste da predição\n",
    "    if country[i] == 'Brasil':\n",
    "        st = strpp[country[i]]\n",
    "        ts = stspp[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_lstm_casos_test_brazil.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_lstm_casos_train_brazil.csv',ts,delimiter=',')\n",
    "    if country[i] == 'Índia':\n",
    "        st = strpp[country[i]]\n",
    "        ts = stspp[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_lstm_casos_test_india.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_lstm_casos_train_india.csv',ts,delimiter=',')\n",
    "    if country[i] == 'Itália':\n",
    "        st = strpp[country[i]]\n",
    "        ts = stspp[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_lstm_casos_test_italia.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_lstm_casos_train_italia.csv',ts,delimiter=',')\n",
    "    if country[i] == 'EUA':\n",
    "        st = strpp[country[i]]\n",
    "        ts = stspp[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_lstm_casos_test_eua.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_lstm_casos_train_eua.csv',ts,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar gráficos com testes do modelo MLP\n",
    "for i in range(len(country)):\n",
    "    print('\\n MLP - O melhor caso - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com MLP' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(testP[country[i]], label = 'Dados reais')\n",
    "    plt.plot(stestPredMLP[country[i]], label = 'Predição')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('Test Score: %.2f RMSE' % (stssMLP[country[i]]))\n",
    "    print('MAE:', stsmMLP[country[i]])\n",
    "    print('Taxa de aprendizagem:', st_aMLP[country[i]])\n",
    "    print('Dropout:', sdropoutMLP[country[i]])\n",
    "    print('Número de células por camada:',sn_neu[country[i]])\n",
    "\n",
    "\n",
    "    print('\\n MLP - O segundo melhor - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com MLP' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(testP[country[i]], label = 'Dados reais')\n",
    "    plt.plot(testPredMLP[country[i]], label = 'Predição')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('Test Score: %.2f RMSE' % (tssMLP[country[i]]))\n",
    "    print('Taxa de aprendizagem:', t_aMLP[country[i]])\n",
    "    print('Dropout:', dropoutMLP[country[i]])\n",
    "    print('MAE:', tsmMLP[country[i]])\n",
    "    print('Número de células por camada:',n_neu[country[i]])\n",
    " \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotar gráficos com base nas previsões do modelo MLP\n",
    "for i in range(len(country)):\n",
    "    print('\\n MLP - O melhor caso - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com MLP' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(dts[country[i]], label = 'Dados reais')\n",
    "    plt.plot(strppMLP[country[i]], label = 'Predição de treino')\n",
    "    plt.plot(stsppMLP[country[i]], label = 'Predição de teste')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Train Score: %.2f RMSE' % (strsMLP[country[i]]))\n",
    "    print('Test Score: %.2f RMSE' % (stssMLP[country[i]]))\n",
    "    print('MAE:', stsmMLP[country[i]])\n",
    "    print('Taxa de aprendizagem:', st_aMLP[country[i]])\n",
    "    print('Dropout:', sdropoutMLP[country[i]])\n",
    "    print('Número de células por camada:',sn_neu[country[i]])\n",
    "\n",
    "\n",
    "    print('\\n MLP - O segundo melhor - %s \\n' %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com MLP' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(dts[country[i]], label = 'Dados reais')\n",
    "    plt.plot(trppMLP[country[i]], label = 'Predição de treino')\n",
    "    plt.plot(tsppMLP[country[i]], label = 'Predição de teste')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Train Score: %.2f RMSE' % (trsMLP[country[i]]))\n",
    "    print('Test Score: %.2f RMSE' % (tssMLP[country[i]]))\n",
    "    print('Taxa de aprendizagem:', t_aMLP[country[i]])\n",
    "    print('Dropout:', dropoutMLP[country[i]])\n",
    "    print('MAE:', tsmMLP[country[i]])\n",
    "    print('Número de células por camada:',n_neu[country[i]])\n",
    " \n",
    "    print('\\n\\n')\n",
    "        \n",
    "    if country[i] == 'Brasil':\n",
    "        st = strppMLP[country[i]]\n",
    "        ts = stsppMLP[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_mlp_casos_test_brazil.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_mlp_casos_train_brazil.csv',ts,delimiter=',')\n",
    "    if country[i] == 'Índia':\n",
    "        st = strppMLP[country[i]]\n",
    "        ts = stsppMLP[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_mlp_casos_test_india.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_mlp_casos_train_india.csv',ts,delimiter=',')\n",
    "    if country[i] == 'Itália':\n",
    "        st = strppMLP[country[i]]\n",
    "        ts = stsppMLP[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_mlp_casos_test_italia.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_mlp_casos_train_italia.csv',ts,delimiter=',')\n",
    "    if country[i] == 'EUA':\n",
    "        st = strppMLP[country[i]]\n",
    "        ts = stsppMLP[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_mlp_casos_test_eua.csv',st,delimiter=',')\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/train/out_mlp_casos_train_eua.csv',ts,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do modelo Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = ['Brasil', 'Índia', 'Itália', 'EUA'] #Lista de países\n",
    "for i in range(len(country)):\n",
    "    if country[i] == \"Brasil\":\n",
    "        dataframe = read_csv(\"datasets/countries/casos_covid19_brazil_date.csv\",encoding='utf-8',index_col='date')\n",
    "\n",
    "    if country[i] == \"Índia\":\n",
    "        dataframe = read_csv(\"datasets/countries/casos_covid19_india_date.csv\",encoding='utf-8',index_col='date')\n",
    "        \n",
    "    if country[i] == \"Itália\":\n",
    "        dataframe = read_csv(\"datasets/countries/casos_covid19_italy_date.csv\",encoding='utf-8',index_col='date')\n",
    "\n",
    "    if country[i] == \"EUA\":\n",
    "        dataframe = read_csv(\"datasets/countries/casos_covid19_us_date.csv\",encoding='utf-8',index_col='date')\n",
    "    total = len(dataframe)\n",
    "    t = int(total*0.33)\n",
    "    treino=dataframe.iloc[:-t]\n",
    "    teste=dataframe.iloc[-t:]\n",
    "    #Implementando modelos\n",
    "    model1=SimpleExpSmoothing(treino).fit(smoothing_level=0.111,optimized=True)\n",
    "    modelo1=model1.forecast(len(teste))\n",
    "    model2=Holt(treino).fit(smoothing_level=0.7187)\n",
    "    modelo2=model2.forecast(len(teste))\n",
    "    model3=ExponentialSmoothing(treino,trend='add',seasonal='add').fit()\n",
    "    modelo3=model3.forecast(len(teste))\n",
    "    model4=ExponentialSmoothing(treino,trend='add',seasonal='mul').fit()\n",
    "    modelo4=model4.forecast(len(teste))\n",
    "    model5=ExponentialSmoothing(treino,trend='mul',seasonal='add').fit()\n",
    "    modelo5=model5.forecast(len(teste))\n",
    "    #plt.plot(teste)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    modelo1.plot(figsize=(16,8))\n",
    "    modelo2.plot()\n",
    "    modelo3.plot()\n",
    "    modelo4.plot()\n",
    "    modelo5.plot()\n",
    "    plt.title(\"Predições (ES) de casos confirmados de COVID19 - (%s)\" %(country[i]), size=15)\n",
    "    plt.xticks(size=15)\n",
    "    plt.yticks(size=15)\n",
    "    lista=['Método 1','Método 2','Método 3','Método 4','Método 5']\n",
    "    plt.legend(lista)\n",
    "    plt.show()\n",
    "    print('*************Métricas do Algoritmo de Suavização Simples*************')\n",
    "    print(' '*254)\n",
    "    print('Erro médio absoluto do Algoritmo de Suavização Simples :',round(mean_absolute_error(teste,modelo1),3))\n",
    "    print('Raiz do erro médio quadrado do Algoritmo de Suavização Simples :',round(mean_squared_error(teste,modelo1)**0.5,3))\n",
    "\n",
    "\n",
    "    print(' '*254)\n",
    "    print('*************Métricas do Algoritmo de Suavização de Holt*************')\n",
    "    print(' '*254)\n",
    "    print('Erro médio absoluto do Algoritmo de Suavização Holt:',round(mean_absolute_error(teste,modelo2),3))\n",
    "    print('Raiz do erro médio quadrado do Algoritmo de Suavização',round(mean_squared_error(teste,modelo2)**0.5,3))\n",
    "\n",
    "    print(' '*254)\n",
    "    print('*************Métricas do Algoritmo de Suavização de Holt-Winters aditivo*************')\n",
    "    print(' '*254)\n",
    "    print('Erro médio absoluto do Algoritmo de Suavização Holt-Winters aditivo :', round(mean_absolute_error(teste,modelo3),3))\n",
    "    print('Raiz do erro médio quadrado do Algoritmo de Suavização Holt-Winters aditivo :',round(mean_squared_error(teste,modelo3)**0.5,3))\n",
    "\n",
    "    print(' '*254)\n",
    "    print('*************Métricas do Algoritmo de Suavização de Holt-Winters multiplicativo*************')\n",
    "    print(' '*254)\n",
    "    print('Erro médio absoluto do Algoritmo de Suavização Holt-Winters multiplicativo :',round(mean_absolute_error(teste,modelo4),3))\n",
    "    print('Raiz do erro médio quadrado do Algoritmo de Suavização Holt-Winters multiplicativo :',round(mean_squared_error(teste,modelo4)**0.5,3))\n",
    "\n",
    "    print(' '*254)\n",
    "    print('*************Métricas do Algoritmo de Suavização de Pegels aditivo *************')\n",
    "    print(' '*254)\n",
    "    print('Erro médio absoluto do Algoritmo de Suavização Pegels aditivo :',round(mean_absolute_error(teste,modelo5),3))\n",
    "    print('Raiz do erro médio quadrado do Algoritmo de Suavização Pegels aditivo :',round(mean_squared_error(teste,modelo5)**0.5,3))\n",
    "\n",
    "    print(' '*254)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Dicionários\n",
    "p = [1,2,3,4,5]\n",
    "d = [1,2,3,4,5]\n",
    "q = [1,1,3,1,5]\n",
    "sp = {}\n",
    "sd = {}\n",
    "sq = {}\n",
    "sps = {}\n",
    "sds = {}\n",
    "sqs = {}\n",
    "pred = {}\n",
    "preds = {}\n",
    "out = {}\n",
    "rmses = {}\n",
    "maes = {}\n",
    "maess = {}\n",
    "rmsess = {'Brasil':(9**15), 'Índia':(9**15), 'EUA':(9**15),'Itália':(9**15)} #Dicionário de scores de testes\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "country = ['Brasil', 'Índia', 'Itália', 'EUA'] #Lista de países\n",
    "# load dataset\n",
    "for i in range(len(country)):\n",
    "    for z in range(len(p)):\n",
    "        if country[i] == 'Brasil':\n",
    "            series = read_csv('datasets/countries/casos_covid19_brazil.csv', usecols=[1], engine='python')\n",
    "        if country[i] == 'Índia':\n",
    "            series = read_csv('datasets/countries/casos_covid19_india.csv', usecols=[1], engine='python')\n",
    "        if country[i] == 'Itália':\n",
    "            series = read_csv('datasets/countries/casos_covid19_italy.csv', usecols=[1], engine='python')\n",
    "        if country[i] == 'EUA':\n",
    "            series = read_csv('datasets/countries/casos_covid19_us.csv', usecols=[1], engine='python')\n",
    "        # split into train and test sets\n",
    "        X = series.values\n",
    "        size = int(len(X) * 0.66)\n",
    "        train, test = X[0:size], X[size:len(X)]\n",
    "        history = [x for x in train]\n",
    "        predictions = list()\n",
    "        # walk-forward validation\n",
    "        for t in range(len(test)):\n",
    "            model = ARIMA(history, order=(p[z],d[z],q[z]))\n",
    "            model_fit = model.fit()\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "            #print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "            # evaluate forecasts\n",
    "        mae = mean_absolute_error(test, predictions)\n",
    "        rmse = math.sqrt(mean_squared_error(test, predictions))\n",
    "        maes[country[i]] = mae\n",
    "        rmses[country[i]] = rmse\n",
    "        pred[country[i]] = predictions\n",
    "        out[country[i]] = test\n",
    "        sp[country[i]] = p[z]\n",
    "        sd[country[i]] = d[z]\n",
    "        sq[country[i]] = q[z]\n",
    "        if rmses[country[i]] < rmsess[country[i]]:\n",
    "            sps[country[i]] = p[z]\n",
    "            sds[country[i]] = d[z]\n",
    "            sqs[country[i]] = q[z]\n",
    "            maess[country[i]] = mae\n",
    "            rmsess[country[i]] = rmse\n",
    "            preds[country[i]] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(country)):\n",
    "    print(\"\\nARIMA - O melhor caso - %s\\n\" %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com ARIMA' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(out[country[i]], label = 'Dados reais', color = 'blue')\n",
    "    plt.plot(preds[country[i]], label = 'Predição', color='red')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Test RMSE: %.3f\\n\\n' % rmsess[country[i]])\n",
    "    print('Test MAE: %.3f\\n\\n' % maess[country[i]])\n",
    "    print(\"p:\", sps[country[i]],\"d:\",sds[country[i]],\"q:\",sqs[country[i]])\n",
    "    \n",
    "    print(\"\\nARIMA - O segundo melhor caso - %s\\n\" %(country[i]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title('Predição de casos confirmados de COVID19 (%s) com ARIMA' %(country[i]))\n",
    "    plt.ylabel('Casos confirmados')\n",
    "    plt.xlabel('Quantidade de dias')\n",
    "    plt.plot(out[country[i]], label = 'Dados reais',color='blue')\n",
    "    plt.plot(pred[country[i]], label = 'Predição', color='red')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('Test RMSE: %.3f\\n\\n' % rmses[country[i]])\n",
    "    print('Test MAE: %.3f\\n\\n' % maes[country[i]])\n",
    "    print(\"p:\", sp[country[i]],\"d:\",sd[country[i]],\"q:\",sq[country[i]])\n",
    "\n",
    "\n",
    "    #Armazenando predições\n",
    "    if country[i] == 'Brasil':\n",
    "        st = preds[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_arima_casos_test_brazil.csv',st,delimiter=',')\n",
    "        \n",
    "    if country[i] == 'Índia':\n",
    "        st = preds[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_arima_casos_test_india.csv',st,delimiter=',')\n",
    "            \n",
    "    if country[i] == 'Itália':\n",
    "        st = preds[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_arima_casos_test_italia.csv',st,delimiter=',')\n",
    "           \n",
    "    if country[i] == 'EUA':\n",
    "        st = preds[country[i]]\n",
    "        numpy.savetxt('C:/Users/Saulo Joel/GitHub/COVID-19-time-series-predictions/outputs/test/out_mlp_casos_test_eua.csv',st,delimiter=',')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
